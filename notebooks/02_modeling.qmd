---
title: "Model fitting and evaluation"
format: html
editor: visual
---

## Setup

```{r}
# machine learning packages
library(tidymodels) # for modeling workflows
library(here)
library(sf)
library(coda)
library(DALEXtra)
library(butcher)
library(bundle)
source(here('R/helpers.R'))

# for parallel processing
library(future) 

mexico_bbox <- st_bbox(c(xmin = -106, xmax = -87, ymin = 13, ymax = 23),
                       crs = 4326) |>
  st_transform(eck4)


train_bbox <- st_bbox(c(xmin = -115, xmax = -50, ymin = -90, ymax = 90),
                       crs = 4326) |>
  st_transform(eck4)

rm1 <- terra::rast(here('data/raw/isotope_predictors/rm1_reproj.tif'))
```

### Load Data

```{r}
dat <- readRDS(here('data/derived/dat.rds')) |>
  filter(!if_any(c(bedrock_age_sr_gradient:distance), is.na)) |> 
  mutate(Sr = logit_transform(Sr)) |>
  mutate(mexico = lengths(st_intersects(geometry, st_as_sfc(mexico_bbox))) > 0) |>
  st_crop(train_bbox) |>
  select(-c(starts_with('sediment'), nitrogen, phosphorus, pyroclastic))
  
train <- dat |>
  filter(!mexico) |>
  select(-mexico) 

test <- dat |>
  filter(mexico) |>
  select(-mexico) |>
  mutate(type2 = replace_na(type2, ''), 
         material = replace_na(material, ''))

train_mean <- mean(train$Sr)
train_sd <- sd(train$Sr)
```

```{r}
mapview::mapview(train) + mapview::mapview(test, color = 'red')
```

### Data Splits

```{r}
# initial splits
splits <- make_splits(train, test)
splits_oaxaca <- make_splits(bind_rows(train, filter(test, !oaxaca)), filter(test, oaxaca))
splits_mexico <- make_splits(train, filter(test, !oaxaca))
# calculate cv folds

mexico_folds <- manual_rset(list(splits_mexico,  # 5 replications
                                 splits_mexico, 
                                 splits_mexico, 
                                 splits_mexico, 
                                 splits_mexico), ids = as.character(1:5)) 

# for spatial cv (not used)
#set.seed(1111)
#folds <- group_vfold_cv(train, group = seqnum,  v = 8, repeats = 2, balance = 'observations')
```

## Model Fitting

### Modeling Workflow

Define the recipe for the modeling workflow.

```{r}
rec <- recipe(Sr ~ ., train) |> 
  update_role(c(geometry, oaxaca, type, type2, material, seqnum), 
              new_role = 'other') |>
  update_role_requirements('other', bake = FALSE) |> 
### step_naomit(all_predictors(), -starts_with('soil')) |>
  step_impute_knn(starts_with('soil')) |>
  step_normalize(all_numeric_predictors())

bart_mod <- parsnip::bart(mode = 'regression', 
                 trees = tune(),
                 prior_terminal_node_coef = tune(), 
                 prior_terminal_node_expo = tune(),
                 prior_outcome_range = tune()
              ) %>%
  set_engine('dbarts', nskip = 800)

bart_wflw <- workflow(rec, bart_mod)
```

### Hyperparameter Tuning

Set the parameters through automatic estimation via Bayesian optimization. Start with an initial grid of 20 samples, then proceed with the Bayesian iterations. We do this with the spatial cross validation.

#### Initial Grid

```{r}
bart_params <- crossing(
  trees = c(50, 100, 200, 300, 400),
  prior_outcome_range = c(8, 12, 16, 18, 20, 24, 32), 
  prior_terminal_node_coef = c(0.85, 0.9, .95, .99),
  prior_terminal_node_expo = c(1, 1.5, 2)
)
```

use tune grid
```{r}
set.seed(1111)
plan(multisession)

bart_grid <- tune_grid(
   bart_wflw,
   resamples = mexico_folds,
   grid = bart_params,
   control = control_grid(pkgs = 'sf')
 )


plan(sequential)

show_best(bart_grid, n = 20)
show_best(bart_grid, n = 20, metric = 'rsq')
autoplot(bart_grid)
```

#### Bayesian Optimization
```{r}
control <- control_bayes(
  pkgs = 'sf',
  no_improve = 30, 
  uncertain = 5, 
  verbose_iter = TRUE,
  parallel_over = 'everything'
)

set.seed(1111)
plan(multisession)

bart_bayes <- tune_bayes(
   bart_wflw,
   resamples = mexico_folds,
   iter = 60, 
   initial = bart_grid, 
   control = control
 )
plan(sequential)

show_best(bart_bayes, n = 20)
select_by_one_std_err(bart_bayes, trees, 'rmse')
autoplot(bart_bayes)
```

Final workflow
```{r}
bart_wflw_final <- parsnip::bart(mode = 'regression',
                        trees = 400,
                        prior_outcome_range = 15,
                        prior_terminal_node_expo = 1.5,
                        prior_terminal_node_coef = 0.99
) %>%
  set_engine('dbarts', 
             nskip = 800, ndpost = 500, 
             keepevery = 4, nchain = 8, nthread = 8, combinechains = FALSE
  ) %>%
  workflow(rec, .)
```

## Model Evaluation

Fit the finalized workflow and predict on our two test datasets.
```{r}
results_mexico <- last_fit(bart_wflw_final, splits_mexico)
results_oaxaca <- last_fit(bart_wflw_final, splits_oaxaca)
```

Check that both models are converging.
```{r}
convergence(results_mexico)
convergence(results_oaxaca)
```

Look at the performance metrics on the logit scale.
```{r}
list(mexico = collect_metrics(results_mexico),
     oaxaca = collect_metrics(results_oaxaca)) |>
  list_rbind(names_to = 'model')  |>
  select(model, .metric, .estimate) |>
  pivot_wider(names_from = .metric, values_from = .estimate)

extract_workflow(results_mexico) |>
  augment(filter(test, oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

extract_workflow(results_mexico) |>
  augment(filter(test, oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

extract_workflow(results_oaxaca) |>
  augment(filter(test, !oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

extract_workflow(results_oaxaca) |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```

```{r}
bart_final |>
  augment(filter(test, !oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

bart_final |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

bart_final |>
  augment(filter(test, oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

bart_final |>
  augment(filter(test, oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```


Compare to the geological baseline model.
```{r}
baseline_geology <- terra::extract(rm1, test, search_radius = 5000) |>
  select(.pred = (rm1_reproj)) |>
  bind_cols(test) |>
  mutate(Sr = (Sr),
         .pred = logit_transform(.pred)) |>
  mutate(model = 'bedrock')
        
baseline_geology |>
  group_by(oaxaca) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```

And on the original scale.
```{r}
baseline_geology |> 
  filter(!oaxaca) |> # with or without oaxaca?
  group_by(type) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))

list(mexico = collect_predictions(results_mexico),
     oaxaca = collect_predictions(results_oaxaca)) |>
  list_rbind(names_to = 'model') |>
  mutate(across(c(.pred, Sr), inverse_logit_transform)) |>
  bind_rows(baseline_geology |> filter(!oaxaca)) |> # with or without oaxaca?
  group_by(model) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))
```

```{r}
results_mexico |>
  extract_workflow() |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, inverse_logit_transform)) |>
  group_by(type) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))

results_oaxaca |>
  extract_workflow() |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, inverse_logit_transform)) |>
  group_by(type) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))
```


Look at in sample predictions by type for the global data. Note the heteroskedasticity on the original scale.
```{r}
predict(extract_workflow(results_mexico), train, type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_mexico), train)) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(aes(color = type), size = 1) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()
```

And the in and out of sample predictions for the Mexico regional data, without Oaxaca. So the first plot is the performance of the model on the Mexico data trained without seeing it, the second is trained having seen it.

```{r}
predict(extract_workflow(results_mexico), filter(test, !oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_mexico), filter(test, !oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(aes(color = type), size = 1, alpha = 0.3) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()

baseline_geology |>
  filter(!oaxaca) |>
ggplot(aes(Sr, .pred)) +
  geom_point(aes(color = type), size = 1, alpha = 0.3) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()

predict(extract_workflow(results_oaxaca), filter(test, !oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_oaxaca), filter(test, !oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(aes(color = type), size = 1, alpha = 0.3) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()
```

### Predictions on Oaxaca

Train a final model on all the data.
```{r}
bart_final <- fit(bart_wflw_final, dat)
```

Save the model for prediction later.
```{r}
bart_final |> 
  butcher() |>
  bundle() |>
  saveRDS(here('outputs/models/bart_final.rds'))
```

```{r}
convergence(bart_final)
```

Now look at how well three of our models perform on the Oaxaca data. Only the final model includes Oaxaca in the training set. But notice the second and third model are very close, which is great as it suggests the model is not overfitting to the Oaxaca data. That is, the fit does improve, but its not overfitting to the apparent outliers.

```{r}
predict(extract_workflow(results_mexico), filter(test, oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_mexico), filter(test, oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()

predict(extract_workflow(results_oaxaca), filter(test, oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_oaxaca), filter(test, oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()

predict(bart_final, filter(test, oaxaca), type = 'conf_int') |>
  bind_cols(augment(bart_final, filter(test, oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()

baseline_geology |>
  filter(oaxaca) |>
ggplot(aes(Sr, .pred)) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()
```
Interesting enough, the model trained without any data from mexico predicts slightly better on Oaxaca than the one with -- could be a convergence issue? oh, that's only for rsq, but not rmse. interesting.
```{r}
list(mexico = augment(extract_workflow(results_mexico), filter(test, oaxaca)),
     oaxaca = collect_predictions(results_oaxaca),
     full = augment(bart_final, filter(test, oaxaca))) |>
  list_rbind(names_to = 'model') |>
  mutate(across(c(.pred, Sr), inverse_logit_transform)) |>
  bind_rows(filter(baseline_geology, oaxaca)) |> 
  group_by(model) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))
```


## Explainability

### Variable Importance

Use BART's native variable importance. These should all be roughly the same for each model version. It looks like our factor variables (sample type, sediment type) and fertilizer variables aren't used. We should consider dropping those from the final model.
```{r}
varimp(results_mexico)
varimp(results_oaxaca)
varimp(bart_final)
```


```{r}
ggsave(here('outputs/figures/bart_varimp.png'), height = 4, width = 6)
```

### Partial Dependence Plots

These may take a long time to run!
```{r}
explainer <- explain_tidymodels(bart_final, data = dplyr::select(dat, -Sr), y = dat$Sr)
pdp <- model_profile(explainer, variables = as.character(arrange(vars, -varimps)$names[1:12]))
```

```{r}
as_tibble(pdp$agr_profiles) %>%
  mutate(`_yhat_` = inverse_logit_transform(`_yhat_`)) %>%
    ggplot(aes(`_x_`, `_yhat_`)) +
 # geom_line(data = as_tibble(pdp$cp_profiles) |> pivot_longer(bedrock_age_sr_gradient:pyroclastic), aes(`_x_`, `_yhat_`), color = 'black', size = 1.2, alpha = 0.8) +
  geom_line(size = 1.2, alpha = 0.8) +
  facet_wrap(~`_vname_`, scales = 'free') +
  theme_bw() +
  labs(y = 'Sr', x = 'Value')
```


### SHAP analysis
```{r}
montealban <- st_drop_geometry(filter(test, type2 == 'Zapotec')[1,])
# why the warning? is it the geometry column?
shap_montealban <- predict_parts(explainer = explainer, new_observation = montealban, type = "shap", B = 20)

plot(shap_montealban)
```

## Examining Residuals

```{r}
errors <- results_mexico |>
  extract_workflow() |>
  #augment(test) |>
  augment(dat) |>
  mutate(across(.pred:Sr, inverse_logit_transform)) |>
  mutate(error = .pred - Sr,
         error_abs = abs(error)) |>
  arrange(-error_abs) |>
  st_as_sf()
errors
```


```{r}
library(fields) 
library(terra)
any(is.na(errors$error))
tps <- Tps(st_coordinates(errors), errors$error)
# use model to predict values at all locations
r <- terra::crop(rm1, mexico_bbox)
plot(r)
p <- terra::interpolate(r, tps, xyNames = c('X', 'Y'))
p <- mask(p, mexico_predictors[[14]])
plot(p)
plot(rast(mexico_predictions2))
plot(rast(mexico_predictions2) + (p))
```

```{r}
mapview::mapview(st_jitter(errors |> arrange(error_abs), 1000), zcol = 'error_abs')
```

```{r}
ggplot() +
  geom_sf(data = arrange(errors, abs(error)), aes(color = abs(error))) +
  scale_color_viridis_c()
```

```{r}
ggplot() +
  #geom_sf(data = mexico, fill = 'black', color = NA) +
  geom_stars(data = mexico_predictions2 |> setNames('Sr')) +
  geom_sf(data = mexico, fill = NA, linewidth = .1, color = 'white') +
  #  geom_sf(data = mexico, fill = NA, color = 'white') +
  coord_sf(expand = FALSE) +
  scale_fill_viridis_c(option = 'magma', na.value = NA, 
             #limits = c(0.7033230, 0.7221751)
             ) +
  geom_sf(data = errors, aes(color = error)) +
  theme_bw() +
  theme(
    panel.background = element_rect(fill = "lightblue"),
    panel.grid.major = element_line(color = "white", linewidth = 0.5),
        plot.margin = margin(0, 0, 0, 0)
  ) +
  labs(x = '', y = '') + 
  ggspatial::annotation_scale(location = "bl", width_hint = 0.2) +
  ggspatial::annotation_north_arrow(
    location = "bl", 
    which_north = "true",
    pad_x = unit(0.2, "in"), 
    pad_y = unit(0.2, "in"),
    style = ggspatial::north_arrow_fancy_orienteering
  )
```
