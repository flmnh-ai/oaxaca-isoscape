---
title: "Model fitting and evaluation"
format: html
editor: visual
---

## Setup

```{r}
# machine learning packages
library(tidymodels) # for modeling workflows
library(here)
library(sf)
library(coda)
library(DALEXtra)
library(butcher)
library(bundle)
source(here('R/helpers.R'))

# for parallel processing
library(future) 

mexico_bbox <- st_bbox(c(xmin = -106, xmax = -87, ymin = 13, ymax = 23),
                       crs = 4326) |>
  st_transform(eck4)


train_bbox <- st_bbox(c(xmin = -115, xmax = -50, ymin = -90, ymax = 90),
                       crs = 4326) |>
  st_transform(eck4)

rm1 <- terra::rast(here('data/raw/isotope_predictors/rm1_reproj.tif'))
```

### Load Data

```{r}
dat <- readRDS(here('data/derived/dat.rds')) |>
  filter(!if_any(c(bedrock_age_sr_gradient:distance), is.na)) |> 
  mutate(Sr = logit_transform(Sr)) |>
  mutate(mexico = lengths(st_intersects(geometry, st_as_sfc(mexico_bbox))) > 0) |>
  st_crop(train_bbox) |>
  select(-sediment) # remove sediment here!
  
train <- dat |>
  filter(!mexico) |>
  select(-mexico) 

test <- dat |>
  filter(mexico) |>
  select(-mexico) |>
  mutate(type2 = replace_na(type2, ''), 
         material = replace_na(material, ''))
```

```{r}
mapview::mapview(train) + mapview::mapview(test, color = 'red')
```

### Data Splits

```{r}
# initial splits
splits <- make_splits(train, test) # train on north and south america, test on mesoamerica and oaxaca
splits_oaxaca <- make_splits(bind_rows(train, filter(test, !oaxaca)), filter(test, oaxaca)) # train on north+south+mesoamerica, test on oaxaca
splits_mexico <- make_splits(train, filter(test, !oaxaca)) # train on north+south america, test on mesoamerica

# calculate cv folds
mexico_folds <- manual_rset(list(splits_mexico,  # 5 replications
                                 splits_mexico, 
                                 splits_mexico, 
                                 splits_mexico, 
                                 splits_mexico), ids = as.character(1:5)) 
```

## Model Fitting

### Modeling Workflow

Define the recipe for the modeling workflow.

```{r}
rec <- recipe(Sr ~ ., train) |> 
  update_role(c(geometry, oaxaca, type, type2, material, seqnum), 
              new_role = 'other') |>
  update_role_requirements('other', bake = FALSE) |> 
  step_impute_knn(starts_with('soil')) |> # impute some soil points on coastal/urban pixels
  step_normalize(all_numeric_predictors()) # normalize to help convergence

bart_mod <- parsnip::bart(mode = 'regression', 
                 trees = tune(),
                 prior_terminal_node_coef = tune(), 
                 prior_terminal_node_expo = tune(),
                 prior_outcome_range = tune()
              ) %>%
  set_engine('dbarts', nskip = 800)

bart_wflw <- workflow(rec, bart_mod)
```

### Hyperparameter Tuning

Set the parameters through automatic estimation via Bayesian optimization. Start with an initial grid of 20 samples, then proceed with the Bayesian iterations. We do this with the spatial cross validation.

#### Initial Grid

```{r}
bart_params <- crossing(
  trees = c(50, 100, 200, 300, 400),
  prior_outcome_range = c(8, 12, 16, 18, 20, 24, 32), 
  prior_terminal_node_coef = c(0.85, 0.9, .95, .99),
  prior_terminal_node_expo = c(1, 1.5, 2)
)
```

use tune grid
```{r}
set.seed(1111)
plan(multisession)

bart_grid <- tune_grid(
   bart_wflw,
   resamples = mexico_folds,
   grid = bart_params,
   control = control_grid(pkgs = 'sf')
 )


plan(sequential)

show_best(bart_grid, n = 20)
show_best(bart_grid, n = 20, metric = 'rsq')
autoplot(bart_grid)
```

#### Bayesian Optimization
```{r}
control <- control_bayes(
  pkgs = 'sf',
  no_improve = 30, 
  uncertain = 5, 
  verbose_iter = TRUE,
  parallel_over = 'everything'
)

set.seed(1111)
plan(multisession)

bart_bayes <- tune_bayes(
   bart_wflw,
   resamples = mexico_folds,
   iter = 60, 
   initial = bart_grid, 
   control = control
 )
plan(sequential)

show_best(bart_bayes, n = 20)
select_by_one_std_err(bart_bayes, trees, 'rmse')
autoplot(bart_bayes)
```

Final workflow
```{r}
bart_wflw_final <- parsnip::bart(mode = 'regression',
                        trees = 400,
                        prior_outcome_range = 15,
                        prior_terminal_node_expo = 1.5,
                        prior_terminal_node_coef = 0.99
) %>%
  set_engine('dbarts', 
             nskip = 800, ndpost = 500, 
             keepevery = 4, nchain = 8, nthread = 8, combinechains = FALSE
  ) %>%
  workflow(rec, .)
```

## Model Evaluation

Fit the finalized workflow and predict on our two test datasets.
```{r}
set.seed(42)
results_mexico <- last_fit(bart_wflw_final, splits_mexico) # train on north+south america, test on mesoamerica
results_oaxaca <- last_fit(bart_wflw_final, splits_oaxaca) # train on north+south+mesoamerica, test on oaxaca
```

Check that both models are converging.
```{r}
convergence(results_mexico)
convergence(results_oaxaca)
```

Look at the performance metrics:

These are metrics for continental scale training data

Train on north+south america, test on mesoamerica without oaxaca
```{r}
set.seed(42) #make sure we get consistent posterior draws
extract_workflow(results_mexico) |>
  augment(filter(test, !oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

set.seed(42)
extract_workflow(results_mexico) |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```

Train on north+south+mesoamerica, test on mesoamerica (in sample)
```{r}
set.seed(42)
extract_workflow(results_oaxaca) |>
  augment(filter(test, !oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

set.seed(42)
extract_workflow(results_oaxaca) |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```

Train on north+south america, test on oaxaca (no mesoamerica)
```{r}
set.seed(42)
extract_workflow(results_mexico) |>
  augment(filter(test, oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

set.seed(42)
extract_workflow(results_mexico) |>
  augment(filter(test, oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```



Train on north+south+mesoamerica, test on oaxaca (out of sample)
```{r}
set.seed(42)
extract_workflow(results_oaxaca) |>
  augment(filter(test, oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))

set.seed(42)
extract_workflow(results_oaxaca) |>
  augment(filter(test, oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```





```{r}
set.seed(42)
bart_final |>
  augment(filter(test, !oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
set.seed(42)

bart_final |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
set.seed(42)

bart_final |>
  augment(filter(test, oaxaca)) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
set.seed(42)

bart_final |>
  augment(filter(test, oaxaca)) |>
  mutate(across(.pred:Sr, ~inverse_logit_transform(.x))) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))
```


Compare to the geological baseline model.
```{r}
baseline_geology <- terra::extract(rm1, test, search_radius = 5000) |>
  select(.pred = (rm1_reproj)) |>
  bind_cols(test) |>
  mutate(Sr = inverse_logit_transform(Sr)) |>
  mutate(model = 'bedrock')

baseline_geology |>
  group_by(oaxaca) |>
  summarize(rmse = rmse_vec(.pred, Sr),
         rsq = rsq_vec(.pred, Sr))


baseline_geology |>
  group_by(oaxaca) |>
  summarize(rmse = rmse_vec(logit_transform(.pred), logit_transform(Sr)),
         rsq = rsq_vec(logit_transform(.pred), logit_transform(Sr)))
```

And on the original scale.
```{r}
baseline_geology |> 
  filter(!oaxaca) |> # with or without oaxaca?
  group_by(type) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))

list(mexico = collect_predictions(results_mexico),
     oaxaca = collect_predictions(results_oaxaca)) |>
  list_rbind(names_to = 'model') |>
  mutate(across(c(.pred, Sr), inverse_logit_transform)) |>
  bind_rows(baseline_geology |> filter(!oaxaca)) |> # with or without oaxaca?
  group_by(model) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))
```

```{r}
results_mexico |>
  extract_workflow() |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, inverse_logit_transform)) |>
  group_by(type) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))

results_oaxaca |>
  extract_workflow() |>
  augment(filter(test, !oaxaca)) |>
  mutate(across(.pred:Sr, inverse_logit_transform)) |>
  group_by(type) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))
```


Look at in sample predictions by type for the global data. Note the heteroskedasticity on the original scale.
```{r}
predict(extract_workflow(results_mexico), train, type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_mexico), train)) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(aes(color = type), size = 1) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()
```

And the in and out of sample predictions for the Mexico regional data, without Oaxaca. So the first plot is the performance of the model on the Mexico data trained without seeing it, the second is trained having seen it.

```{r}
predict(extract_workflow(results_mexico), filter(test, !oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_mexico), filter(test, !oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(aes(color = type), size = 1, alpha = 0.3) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()

baseline_geology |>
  filter(!oaxaca) |>
ggplot(aes(Sr, .pred)) +
  geom_point(aes(color = type), size = 1, alpha = 0.3) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()

predict(extract_workflow(results_oaxaca), filter(test, !oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_oaxaca), filter(test, !oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(aes(color = type), size = 1, alpha = 0.3) +
  geom_abline() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()
```

### Predictions on Oaxaca

Train a final model on all the data.
```{r}
set.seed(42)
bart_final <- fit(bart_wflw_final, dat)
```

Save the model for prediction later.
```{r}
bart_final |> 
  butcher() |>
  bundle() |>
  saveRDS(here('outputs/models/bart_final.rds'))
```

```{r}
convergence(bart_final)
```

Now look at how well three of our models perform on the Oaxaca data. Only the final model includes Oaxaca in the training set. But notice the second and third model are very close, which is great as it suggests the model is not overfitting to the Oaxaca data. That is, the fit does improve, but its not overfitting to the apparent outliers.

```{r}
predict(extract_workflow(results_mexico), filter(test, oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_mexico), filter(test, oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()

predict(extract_workflow(results_oaxaca), filter(test, oaxaca), type = 'conf_int') |>
  bind_cols(augment(extract_workflow(results_oaxaca), filter(test, oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()

predict(bart_final, filter(test, oaxaca), type = 'conf_int') |>
  bind_cols(augment(bart_final, filter(test, oaxaca))) |>
  mutate(across(.pred_lower:Sr, inverse_logit_transform)) |>
  ggplot(aes(Sr, .pred)) +
  geom_linerange(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = .1) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()

baseline_geology |>
  filter(oaxaca) |>
ggplot(aes(Sr, .pred)) +
  geom_point(size = 1) +
  geom_abline() +
  coord_equal() +
  theme_bw()
```
Interesting enough, the model trained without any data from mexico predicts slightly better on Oaxaca than the one with -- could be a convergence issue? oh, that's only for rsq, but not rmse. interesting.
```{r}
list(mexico = augment(extract_workflow(results_mexico), filter(test, oaxaca)),
     oaxaca = collect_predictions(results_oaxaca),
     full = augment(bart_final, filter(test, oaxaca))) |>
  list_rbind(names_to = 'model') |>
  mutate(across(c(.pred, Sr), inverse_logit_transform)) |>
  bind_rows(filter(baseline_geology, oaxaca)) |> 
  group_by(model) |>
  summarize(rmse = rmse_vec(Sr, .pred),
            rsq = rsq_vec(Sr, .pred))
```


## Explainability

### Variable Importance

Use BART's native variable importance. These should all be roughly the same for each model version. It looks like our factor variables (sample type, sediment type) and fertilizer variables aren't used. We should consider dropping those from the final model.
```{r}
varimp(results_mexico)
varimp(results_oaxaca)
varimp(bart_final)
```


```{r}
ggsave(here('outputs/figures/bart_varimp.png'), height = 4, width = 6)
```

### Partial Dependence Plots

These may take a long time to run!
```{r}
explainer <- explain_tidymodels(bart_final, data = dplyr::select(dat, -Sr), y = dat$Sr)
pdp <- model_profile(explainer, variables = as.character(arrange(vars, -varimps)$names[1:12]))
```

```{r}
as_tibble(pdp$agr_profiles) %>%
  mutate(`_yhat_` = inverse_logit_transform(`_yhat_`)) %>%
    ggplot(aes(`_x_`, `_yhat_`)) +
 # geom_line(data = as_tibble(pdp$cp_profiles) |> pivot_longer(bedrock_age_sr_gradient:pyroclastic), aes(`_x_`, `_yhat_`), color = 'black', size = 1.2, alpha = 0.8) +
  geom_line(size = 1.2, alpha = 0.8) +
  facet_wrap(~`_vname_`, scales = 'free') +
  theme_bw() +
  labs(y = 'Sr', x = 'Value')
```


### SHAP analysis
```{r}
montealban <- st_drop_geometry(filter(test, type2 == 'Zapotec')[1,])
# why the warning? is it the geometry column?
shap_montealban <- predict_parts(explainer = explainer, new_observation = montealban, type = "shap", B = 20)

plot(shap_montealban)
```

